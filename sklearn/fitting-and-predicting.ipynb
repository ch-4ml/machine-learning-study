{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[원본 링크](https://scikit-learn.org/stable/getting_started.html#fitting-and-predicting-estimator-basics)\n",
    "\n",
    "Getting Started\n",
    "============================\n",
    "\n",
    "이 가이드의 목적은 Scikit-learn이 제공하는 몇 가지 주요 기능을 설명하는 것입니다.<br>\n",
    "머신 러닝 실습(모델 피팅, 예측, 교차 검증 등)에 대한 매우 기본적인 실무 지식을 전제로 합니다.\n",
    "\n",
    "scikit-learn [설치](https://scikit-learn.org/stable/install.html#installation-instructions)에 대한 [설치 지침](https://scikit-learn.org/stable/install.html#installation-instructions)을 참조하세요.\n",
    "\n",
    "Scikit-learn은 지도 및 비지도 학습을 지원하는 오픈 소스 기계 학습 라이브러리입니다.<br>\n",
    "또한 모델 피팅, 데이터 전처리, 모델 선택 및 평가 등 여러 유틸리티를 위한 다양한 툴을 제공합니다.\n",
    "\n",
    "\n",
    "학습과 예측: estimator(추정기) 기초\n",
    "------------------------\n",
    "\n",
    "Scikit-learn은 [estimators](https://scikit-learn.org/stable/glossary.html#term-estimators)라는 수십 개의 내장 기계 학습 알고리즘과 모델이 있습니다.<br>\n",
    "각각의 Estimator는 [fit](https://scikit-learn.org/stable/glossary.html#term-fit) method를 사용하여 학습(일부 데이터에 적합하도록)할 수 있습니다.\n",
    "\n",
    "다음은 [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)를 매우 기본적인 데이터에 적합하게(학습) 하는 간단한 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state = 0)\n",
    "X = [[ 1,  2,  3],  # 2 samples, 3 features\n",
    "     [11, 12, 13]]\n",
    "y = [0, 1]  # classes of each sample\n",
    "clf.fit(X, y)\n",
    "RandomForestClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[fit](https://scikit-learn.org/stable/glossary.html#term-fit) method는 일반적으로 2개의 입력을 받습니다:\n",
    "\n",
    "1. sample matrix 또는 design matrix [X](https://scikit-learn.org/stable/glossary.html#term-x). <b>x</b>의 크기는 일반적으로 <b>(n_samples, n_features)</b>이며, 이것은 표본(sample)이 행으로 표시되고, 형상(feature)이 열로 표현된다는 것을 의미합니다.\n",
    "\n",
    "2. 회귀 분석 작업에 대한 실제 숫자 또는 분류에 대한 정수(또는 기타 이산형 값 집합)인 목표 값 <b>y</b>. 비 지도 학습의 경우에는 <b>y</b>를 지정하지 않아도 됩니다. <b>y</b>는 일반적으로 <b>i</b> th 항목이 <b>x</b>의 <b>i</b> th sample의 목표에 해당하는 id 배열입니다.\n",
    "\n",
    "일부 estimators는 sparse matrices처럼 다른 자료형과 함께 작동하지만, X와 y는 모두 일반적으로 <b>numpy array</b> 또는 [array와 유사한](https://scikit-learn.org/stable/glossary.html#term-array-like) 자료형입니다.\n",
    "\n",
    "estimator가 한 번 학습하면, 새로운 데이터의 목표값을 예측하는 데 사용할 수 있습니다. estimator를 다시 학습시키지 않아도 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)  # predict classes of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4, 5, 6], [14, 15, 16]])  # predict classes of new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Transformer와 전처리기\n",
    "------------------------\n",
    "기계 학습의 흐름은 종종 다른 부분으로 구성됩니다. 일반적인 파이프라인은 데이터를 귀속시키는 전처리 단계와 목표 값을 예측하는 최종 예측기로 구성됩니다. \n",
    "\n",
    "scikit-learn에서 전처리기와 transformer는 estimator 객체와 동일한 API를 따릅니다. (실제로 모두 동일한 BaseEstimator 클래스에서 상속합니다.) transformer 객체에 예측 method는 없지만 새롭게 변환된 sample matrix X를 출력하는 transform method가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1.],\n",
       "       [ 1., -1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = [[0, 15],\n",
    "     [1, -10]]\n",
    "StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다양한 기능에 다양한 transformation을 적용하려는 use-cases를 위해 [ColumnTransformer](https://scikit-learn.org/stable/modules/compose.html#column-transformer)가 설계되어 있습니다.\n",
    "Pipelines: 전처리기와 estimator 연결\n",
    "------------------------\n",
    "Transformer와 estimator(predictor)는 단일 통합 객체인 <b>Pipeline</b>으로 결합될 수 있습니다. pipeline은 일반 estimator와 동일한 API를 제공하기 때문에 <b>fit</b>, <b>predict</b>를 이용해서 학습하고 예측할 수 있습니다. 나중에 알게 되겠지만 파이프라인을 이용하면 데이터 유출, 즉, 학습 데이터의 일부 테스트 데이터가 공개되는 것 또한 방지할 수 있습니다.\n",
    "\n",
    "다음 예제에서는 [Iris(붓꽃) 데이터 셋을 로드](https://scikit-learn.org/stable/datasets/index.html#datasets)해서, 이를 훈련 셋과 테스트 셋으로 나누고 테스트 데이터에 대한 파이프라인의 정확도 점수를 계산합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create a pipeline object\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(random_state=0)\n",
    ")\n",
    "\n",
    "# load the iris dataset and split it into train and test sets\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# fit the whole pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# we can now use it like any other estimator\n",
    "accuracy_score(pipe.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation(모델 평가)\n",
    "------------------------\n",
    "일부 데이터에 모델을 학습시키더라도, 보이지 않는 데이터(테스트 데이터가 아닌 실제 데이터)에 대해서는 잘 예측하지 못 할 수도 있습니다. 모델은 직접 평가될 필요가 있습니다. 우리는 방금 데이터셋을 훈련 셋과 테스트 셋으로 나누는 [<b>train_test_split</b>](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) helper를 보았는데, scikit-learn은 특히 [교차 검증](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)을 위해서 모델 평가를 할 수 있는 다양한 tool을 제공합니다.\n",
    "\n",
    "여기서는 [<b>cross_validate</b>](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) helper를 사용하여 어떻게 5-fold cross-validation 절차를 수행하는지 간략하게 보여줍니다. 또한 수동으로 fold를 반복할 수 있고, 다양한 데이터 분할 전략을 사용하며, custom scoring 기능을 사용할 수 있다는 점에 유의하세요. 자세한 내용은 [사용 설명서](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation)를 참조하세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X, y = make_regression(n_samples=1000, random_state=0)\n",
    "lr = LinearRegression()\n",
    "\n",
    "result = cross_validate(lr, X, y)  # defaults to 5-fold CV\n",
    "result['test_score']  # r_squared score is high because dataset is easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic parameter searches(자동 파라미터 검색)\n",
    "------------------------\n",
    "모든 estimator에는 튜닝할 수 있는 파라미터(hyper-parameters)가 있습니다. estimator의 일반화 성능은 몇 가지 파라미터에 의해 결정됩니다. 예를 들어 [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)에는 숲의 나무 수를 결정하는 <b>n_estimators</b> parameter와, 각각의 트리의 최대 깊이를 결정하는 <b>max_depth</b> 파라미터가 있습니다. 이러한 매개변수는 실제로 마주하고 있는 데이터에 의존하기 때문에 정확한 값이 얼마가 되어야 하는지는 명확하지 않습니다. \n",
    "\n",
    "<b>Scikit-learn</b>은 교차 검증을 통해 자동으로 최적의 파라미터 조합을 찾을 수 있는 도구를 제공합니다. 다음 예제에서는 [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV) 객체를 이용해서 random forest의 파라미터 공간을 무작위로 검색합니다. 검색이 끝나면, [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)는 최적의 매개변수 집합으로 학습한 [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)로 동작합니다. 자세한 내용은 [사용 설명서](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)를 참조하세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7349601117850644"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# define the parameter space that will be searched over\n",
    "param_distributions = {'n_estimators': randint(1, 5),\n",
    "                       'max_depth': randint(5, 10)}\n",
    "\n",
    "# now create a searchCV object and fit it to the data\n",
    "search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=0),\n",
    "                            n_iter=5,\n",
    "                            param_distributions=param_distributions,\n",
    "                            random_state=0)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "search.best_params_\n",
    "\n",
    "# the search object now acts like a normal random forest estimator\n",
    "# with max_depth=9 and n_estimators=4\n",
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: 단일 estimator 대신 [파이프라인을 통해 검색](https://scikit-learn.org/stable/modules/grid_search.html#composite-grid-search)하길 바랍니다. 주요 이유 중 하나는 파이프라인을 사용하지 않고 전처리 단계를 전체 데이터셋에 적용한 다음 어떤 종류의 교차 검증을 수행한다는 것은 훈련 데이터와 테스트 데이터 사이의 독립성에 대한 근본적인 가정을 깨뜨리고 있는 것이기 때문입니다. 실제로 전체 데이터 셋을 사용해서 데이터를 전처리 했으므로 일부 테스트 셋에 대한 정보를 훈련 셋에 사용할 수 있습니다. 이렇게 되면 estimator의 일반화 성능을 과대평가하게 됩니다([과대적합, kaggle post](https://www.kaggle.com/alexisbcook/data-leakage)). 교차 검증을 위해 파이프라인을 사용하는 것은 대체로 이러한 일반적인 함정으로부터 당신을 지켜줄 것입니다.\n",
    "\n",
    "Next steps\n",
    "------------------------\n",
    "[User Guide](https://scikit-learn.org/stable/user_guide.html#user-guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
